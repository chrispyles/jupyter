<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>graduate-admissions.ipynb</title>
  <meta name="description" content="Graduate Admissions">

  <link rel="canonical" href="http://0.0.0.0:4000/notebooks/graduate-admissions/graduate-admissions.html">
  <link rel="alternate" type="application/rss+xml" title="Chris Pyles" href="http://0.0.0.0:4000/feed.xml">

  <meta property="og:url"         content="http://0.0.0.0:4000/notebooks/graduate-admissions/graduate-admissions.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="graduate-admissions.ipynb" />
<meta property="og:description" content="Graduate Admissions" />
<meta property="og:image"       content="" />


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage":
    "http://0.0.0.0:4000/notebooks/graduate-admissions/graduate-admissions.html",
  "headline":
    "graduate-admissions.ipynb",
  "datePublished":
    "2019-04-19T14:02:04-05:00",
  "dateModified":
    "2019-04-19T14:02:04-05:00",
  "description":
    "Graduate Admissions",
  "author": {
    "@type": "Person",
    "name": "Christopher Pyles"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "http://0.0.0.0:4000",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "http://0.0.0.0:4000",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/assets/css/styles.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css ">
  <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="https://cpyles.com/assets/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    CommonHTML: {
        linebreaks: {
            automatic: true,
        },
    },
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML' async></script>

  <!-- DOM updating function -->
  <script>
const runWhenDOMLoaded = cb => {
  if (document.readyState != 'loading') {
    cb()
  } else if (document.addEventListener) {
    document.addEventListener('DOMContentLoaded', cb)
  } else {
    document.attachEvent('onreadystatechange', function() {
      if (document.readyState == 'complete') cb()
    })
  }
}

// Helper function to init things quickly
initFunction = function(myfunc) {
  runWhenDOMLoaded(myfunc);
  document.addEventListener('turbolinks:load', myfunc);
};
</script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="/assets/js/anchor.min.js"  type="text/javascript"></script>
  <script>

initFunction(function () {
    anchors.add("main h1, main h2, main h3, main h4")
});

</script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="/assets/js/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  <script src="https://unpkg.com/nbinteract-core" async></script>

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->


  <!-- Google analytics -->
  <script src="/assets/js/ga.js" async></script>

  <!-- Clipboard copy button -->
  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" async></script>

  <!-- Load JS that depends on site variables -->
  <script>
/**
 * Set up copy/paste for code blocks
 */
const codeCellId = index => `codecell${index}`

const clipboardButton = id =>
  `<a class="btn copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#${id}">
    <img src="/assets/images/copy-button.svg" alt="Copy to clipboard">
  </a>`

// Clears selected text since ClipboardJS will select the text when copying
const clearSelection = () => {
  if (window.getSelection) {
    window.getSelection().removeAllRanges()
  } else if (document.selection) {
    document.selection.empty()
  }
}

// Changes tooltip text for two seconds, then changes it back
const temporarilyChangeTooltip = (el, newText) => {
  const oldText = el.getAttribute('data-tooltip')
  el.setAttribute('data-tooltip', newText)
  setTimeout(() => el.setAttribute('data-tooltip', oldText), 2000)
}

const addCopyButtonToCodeCells = () => {
  // If ClipboardJS hasn't loaded, wait a bit and try again. This
  // happens because we load ClipboardJS asynchronously.
  if (window.ClipboardJS === undefined) {
    setTimeout(addCopyButtonToCodeCells, 250)
    return
  }

  const codeCells = document.querySelectorAll('div.highlighter-rouge:not(.output) pre')
  codeCells.forEach((codeCell, index) => {
    const id = codeCellId(index)
    codeCell.setAttribute('id', id)
    if (document.querySelector(`pre#${id} + a`) == null) {
      codeCell.insertAdjacentHTML('afterend', clipboardButton(id));
    }
  })

  const clipboard = new ClipboardJS('.copybtn')
  clipboard.on('success', event => {
    clearSelection()
    temporarilyChangeTooltip(event.trigger, 'Copied!')
  })

  clipboard.on('error', event => {
    temporarilyChangeTooltip(event.trigger, 'Failed to copy')
  })

  // Get rid of clipboard before the next page visit to avoid memory leak
  document.addEventListener('turbolinks:before-visit', () =>
    clipboard.destroy()
  )
}

initFunction(addCopyButtonToCodeCells);
</script>

  <!-- Hide cell code -->
  
<script>
/**
Add buttons to hide code cells
*/


var setCodeCellVisibility = function(inputField, kind) {
    // Update the image and class for hidden
    var id = inputField.getAttribute('data-id');
    var codeCell = document.querySelector(`#${id}`);

    if (kind === "visible") {
        codeCell.classList.remove('hidden');
        inputField.checked = true;
    } else {
        codeCell.classList.add('hidden');
        inputField.checked = false;
    }
}

var toggleCodeCellVisibility = function (event) {
    // The label is clicked, and now we decide what to do based on the input field's clicked status
    if (event.target.tagName === "LABEL") {
        var inputField = event.target.previousElementSibling;
    } else {
        // It is the span inside the target
        var inputField = event.target.parentElement.previousElementSibling;
    }

    if (inputField.checked === true) {
        setCodeCellVisibility(inputField, "visible");
    } else {
        setCodeCellVisibility(inputField, "hidden");
    }
}


// Button constructor
const hideCodeButton = id => `<input class="hidebtn" type="checkbox" id="hidebtn${id}" data-id="${id}"><label title="Toggle cell" for="hidebtn${id}" class="plusminus"><span class="pm_h"></span><span class="pm_v"></span></label>`

var addHideButton = function () {
  // If a hide button is already added, don't add another
  if (document.querySelector('div.hidecode input') !== null) {
      return;
  }

  // Find the input cells and add a hide button
  document.querySelectorAll('div.input_area div.highlight').forEach(function (item, index) {
    if (!item.parentElement.classList.contains("hidecode")) {
        // Skip the cell if it doesn't have a hidecode class
        return;
    }

    const id = codeCellId(index)
    item.setAttribute('id', id);
    item.insertAdjacentHTML('afterend', hideCodeButton(id))

    // Set up the visibility toggle
    hideLink = document.querySelector(`#${id} + input + label`);
    hideLink.addEventListener('click', toggleCodeCellVisibility)
  });
}


// Initialize the hide buttos
var initHiddenCells = function () {
    // Add hide buttons to the cells
    addHideButton();

    // Toggle the code cells that should be hidden
    document.querySelectorAll('div.hidecode input').forEach(function (item) {
        setCodeCellVisibility(item, 'hidden');
        item.checked = true;
    })
}

initFunction(initHiddenCells);

</script>


  <!-- Load custom website scripts -->
  <script src="/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  

  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="/assets/js/lunr/lunr.min.js" type="text/javascript"></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>
</head>

  <body>
    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://jupyter.org/jupyter-book/intro.html"><img src="" class="textbook_logo" id="sidebar-logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">Chris Pyles</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/index.html"
        >
          
          Projects and Jupyter Notebooks
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/notebooks/insurance/insurance.html"
                >
                  
                  insurance.ipynb
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/notebooks/avocado/avocado.html"
                >
                  
                  avocado.ipynb
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry c-sidebar__entry--active"
                  href="/notebooks/graduate-admissions/graduate-admissions.html"
                >
                  
                  graduate-admissions.ipynb
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/notebooks/movies/movies.html"
                >
                  
                  movies.ipynb
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
  </ul>
  <p class="sidebar_footer"><a href='https://mybinder.org/v2/gh/chrispyles/jupyter/master?filepath=content%2Fnotebooks' target='_blank'><img src='https://mybinder.org/badge_logo.svg' /></a></p>
</nav>

      
      <!-- Shamelessly copied from minimal mistakes -->


<!-- TOC will only show up if it has at least one item -->


  <aside class="sidebar__right">
    <nav class="onthispage">
      <header><h4 class="nav__title"><i class="fa fa-list"></i>   On this page</h4></header>
      <ul class="toc__menu">
  <li><a href="#principal-component-analysis">Principal Component Analysis</a></li>
  <li><a href="#multivariate-linear-regression">Multivariate Linear Regression</a>
    <ul>
      <li><a href="#improving-the-model">Improving the Model</a></li>
      <li><a href="#bootstrapping-the-model">Bootstrapping the Model</a></li>
    </ul>
  </li>
  <li><a href="#sources">Sources</a></li>
</ul>
    </nav>
  </aside>


      
      <main class="c-textbook__page" tabindex="-1">
          <div class="o-wrapper">
            <div class="c-sidebar-toggle">
  <!-- We show the sidebar by default so we use .is-active -->
  <button
    id="js-sidebar-toggle"
    class="hamburger hamburger--arrowalt is-active"
  >
    <span class="hamburger-box">
      <span class="hamburger-inner"></span>
    </span>
    <span class="c-sidebar-toggle__label">Toggle Sidebar</span>
  </button>
</div>

            
<div class="buttons">




</div>


            <div class="c-textbook__content">
              <h1 id="graduate-admissions">Graduate Admissions</h1>

<p>This data set concerns test scores and other admissions variables for a Graduate program and the chance of admission for each student. The first portion of this notebook performs a principal component analysis of the data set in order to reduce its dimensionality. The data set is from <a href="https://www.kaggle.com/mohansacharya/graduate-admissions">Kaggle</a>.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c"># read table</span>
<span class="n">admissions</span> <span class="o">=</span> <span class="p">(</span><span class="n">pd</span>
              <span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'admissions_predictions.csv'</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s">'Serial No.'</span><span class="p">)</span>
              <span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s">'Chance of Admit '</span> <span class="p">:</span> <span class="s">'Chance of Admit'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">admissions</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="output output_html">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GRE Score</th>
      <th>TOEFL Score</th>
      <th>University Rating</th>
      <th>SOP</th>
      <th>LOR</th>
      <th>CGPA</th>
      <th>Research</th>
      <th>Chance of Admit</th>
    </tr>
    <tr>
      <th>Serial No.</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>337</td>
      <td>118</td>
      <td>4</td>
      <td>4.5</td>
      <td>4.5</td>
      <td>9.65</td>
      <td>1</td>
      <td>0.92</td>
    </tr>
    <tr>
      <th>2</th>
      <td>324</td>
      <td>107</td>
      <td>4</td>
      <td>4.0</td>
      <td>4.5</td>
      <td>8.87</td>
      <td>1</td>
      <td>0.76</td>
    </tr>
    <tr>
      <th>3</th>
      <td>316</td>
      <td>104</td>
      <td>3</td>
      <td>3.0</td>
      <td>3.5</td>
      <td>8.00</td>
      <td>1</td>
      <td>0.72</td>
    </tr>
    <tr>
      <th>4</th>
      <td>322</td>
      <td>110</td>
      <td>3</td>
      <td>3.5</td>
      <td>2.5</td>
      <td>8.67</td>
      <td>1</td>
      <td>0.80</td>
    </tr>
    <tr>
      <th>5</th>
      <td>314</td>
      <td>103</td>
      <td>2</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>8.21</td>
      <td>0</td>
      <td>0.65</td>
    </tr>
  </tbody>
</table>
</div>
</div>

<h2 id="principal-component-analysis">Principal Component Analysis</h2>
<p>Principal component analysis (PCA) is a tool to help visualize higher-dimensional data in 2 dimensions (e.g. as a scatterplot). It is founded in the linear algebra technique of singular value decomposition. For a detailed explanation of PCA, see the PCA section of my <a href="../avocado/avocado#principal-component-analysis">avocado notebook</a>. To begin performing the PCA, we first make a scree plot to determine if the data can be well represented in 2 dimensions.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># extracting the df as a numpy matrix</span>
<span class="n">admissions_matrix</span> <span class="o">=</span> <span class="n">admissions</span><span class="o">.</span><span class="n">values</span>

<span class="c"># normalizing the data within each column</span>
<span class="n">normed_admissions</span> <span class="o">=</span> <span class="p">(</span><span class="n">admissions_matrix</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">admissions_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">admissions_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c"># performing SVD on the matrix</span>
<span class="n">u</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">normed_admissions</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># plotting the scree plot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Scree Plot of Principal Components'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Principal Component Number'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Variance (Component Scores)'</span><span class="p">);</span>
</code></pre></div></div>

<p class="output output_png"><img src="../../images/notebooks/graduate-admissions/graduate-admissions_4_0.png" alt="png" /></p>

<p>Based on how high PC1 and PC2 are relative to the other principal components, the data should be well-represented in 2D. We now use <code class="highlighter-rouge">seaborn</code> to plot a scatterplot of PC2 vs. PC1.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">admissions_2d</span> <span class="o">=</span> <span class="n">normed_admissions</span> <span class="err">@</span> <span class="n">vt</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">admissions_2d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">admissions_2d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"PC2 vs. PC2 for Graduate Admissions Data"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Principal Component 1"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Principal Component 2"</span><span class="p">);</span>
</code></pre></div></div>

<p class="output output_png"><img src="../../images/notebooks/graduate-admissions/graduate-admissions_6_0.png" alt="png" /></p>

<h2 id="multivariate-linear-regression">Multivariate Linear Regression</h2>

<p>The next thing to look at is building a linear regression predictor of the chance of admission using the data set. This predictor will take in the values in all of the columns (except <code class="highlighter-rouge">Chance of Admit</code>) and predict the chance of admission for that student. The model will be build using the <code class="highlighter-rouge">linear_model</code> sublibrary of <code class="highlighter-rouge">scikit-learn</code>, a machine learning library in Python.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># to refresh our memory</span>
<span class="n">admissions</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="output output_html">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>GRE Score</th>
      <th>TOEFL Score</th>
      <th>University Rating</th>
      <th>SOP</th>
      <th>LOR</th>
      <th>CGPA</th>
      <th>Research</th>
      <th>Chance of Admit</th>
    </tr>
    <tr>
      <th>Serial No.</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>337</td>
      <td>118</td>
      <td>4</td>
      <td>4.5</td>
      <td>4.5</td>
      <td>9.65</td>
      <td>1</td>
      <td>0.92</td>
    </tr>
    <tr>
      <th>2</th>
      <td>324</td>
      <td>107</td>
      <td>4</td>
      <td>4.0</td>
      <td>4.5</td>
      <td>8.87</td>
      <td>1</td>
      <td>0.76</td>
    </tr>
    <tr>
      <th>3</th>
      <td>316</td>
      <td>104</td>
      <td>3</td>
      <td>3.0</td>
      <td>3.5</td>
      <td>8.00</td>
      <td>1</td>
      <td>0.72</td>
    </tr>
    <tr>
      <th>4</th>
      <td>322</td>
      <td>110</td>
      <td>3</td>
      <td>3.5</td>
      <td>2.5</td>
      <td>8.67</td>
      <td>1</td>
      <td>0.80</td>
    </tr>
    <tr>
      <th>5</th>
      <td>314</td>
      <td>103</td>
      <td>2</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>8.21</td>
      <td>0</td>
      <td>0.65</td>
    </tr>
  </tbody>
</table>
</div>
</div>

<p>The values in most of the columns are self-explanatory, and the distances between the discrete values of the columns so small that they will be treated as continuous variables in the model. The only exceptions to this rule are the <code class="highlighter-rouge">University Rating</code> and <code class="highlighter-rouge">Research</code> columns. The <code class="highlighter-rouge">University Rating</code> column represents an ordinal variable with possible values 1, 2, 3, 4, and 5:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">admissions</span><span class="p">[</span><span class="s">'University Rating'</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="output output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([4, 3, 2, 5, 1])
</code></pre></div></div>

<p>The <code class="highlighter-rouge">Research</code> column represents whether or not a student has engaged in research and takes on the value <code class="highlighter-rouge">1</code> (yes) or <code class="highlighter-rouge">0</code> (no):</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">admissions</span><span class="p">[</span><span class="s">'Research'</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="output output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([1, 0])
</code></pre></div></div>

<p>To account for these variables, our data processing will <a href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f">one-hot encode</a> the <code class="highlighter-rouge">University Rating</code> variable. Because the <code class="highlighter-rouge">Research</code> variable only has possible values 0 and 1, it is already one-hot encoded for us. The function <code class="highlighter-rouge">process_data</code> below takes in a dataframe and performs the one-hot encoding on the <code class="highlighter-rouge">University Rating</code> variable. It returns a dataframe that does not contain the <code class="highlighter-rouge">Chance of Admit</code> column and a vector with the <code class="highlighter-rouge">Chance of Admit</code> values.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">process_data</span><span class="p">(</span><span class="n">original_data</span><span class="p">):</span>
    <span class="s">"""
    Processes data for use in linear regression model
    """</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">original_data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    
    <span class="c"># one hot encode 'University Rating'</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>
                          <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'University Rating'</span><span class="p">],</span>
                          <span class="n">drop_first</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Chance of Admit'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Chance of Admit'</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</code></pre></div></div>

<p>In order to test the accuracy of our model, we first need to split our data into a training set and a testing set; we use the function <code class="highlighter-rouge">train_test_split</code> from <code class="highlighter-rouge">sklearn.model_selection</code> to accomplish this.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">admissions</span><span class="p">)</span>
</code></pre></div></div>

<p>In the cell below, we finally construct our linear regression model and predict the <code class="highlighter-rouge">Chance of Admit</code> values for the training and testing sets. This is done by applying the <code class="highlighter-rouge">process_data</code> function to each set, fitting the model to the training data, and running the predictor on the training and testing data.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="n">lm</span>

<span class="c"># intialize the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>

<span class="c"># process the data</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">process_data</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">process_data</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="c"># fit the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c"># predict for the training and testing sets</span>
<span class="n">y_fitted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<p>To assess the accuracy of our model, we will use the root-mean-squared error. If our predicted vector is $\mathbf{\hat{y}}$ and the original data is $\mathbf{y}$, this error function has the formula</p>

<script type="math/tex; mode=display">RMSE(\mathbf{\hat{y}}, \mathbf{y}) = \sqrt{ \frac{1}{n} \sum_{i=1}^n \left ( \hat{y}_i - y_i \right ) ^2 }</script>

<p>The function <code class="highlighter-rouge">rmse</code> defined below takes in an array of predicted and original data and returns the RMSE from the above formula.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">actual</span><span class="p">):</span>
    <span class="s">"""
    Returns the RMSE of a model
    """</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predicted</span> <span class="o">-</span> <span class="n">actual</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

<span class="n">train_rmse</span> <span class="o">=</span> <span class="n">rmse</span><span class="p">(</span><span class="n">y_fitted</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">test_rmse</span> <span class="o">=</span> <span class="n">rmse</span><span class="p">(</span><span class="n">y_predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Training RMSE: {}</span><span class="se">\n</span><span class="s">Test RMSE: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_rmse</span><span class="p">,</span> <span class="n">test_rmse</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="improving-the-model">Improving the Model</h3>

<p>Before constructing our model, we assumed that all of the variables in the data had a linear relationship with the <code class="highlighter-rouge">Chance of Admit</code> variable. This, however, is possibly erroneous, and to improve the accuracy of our model we should check that assumption. To that end, in the cell below, we plot scatterplots of <code class="highlighter-rouge">Chance of Admit</code> versus each variable in the data.</p>

<div class="language-python input_area hidecode highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">'Scatterplots of Chance of Admit against Admissions Criteria'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=.</span><span class="mi">93</span><span class="p">)</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">admissions</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Chance of Admit'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">admissions</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">admissions</span><span class="p">[</span><span class="s">'Chance of Admit'</span><span class="p">])</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div>

<p class="output output_png"><img src="../../images/notebooks/graduate-admissions/graduate-admissions_22_0.png" alt="png" /></p>

<p>From the plots above, it looks like the <code class="highlighter-rouge">Research</code> variable is not too well correlated with <code class="highlighter-rouge">Chance of Admit</code>, so in our fine-tuned model we will remove it from consideration. Also note that the <code class="highlighter-rouge">CGPA</code> curve looks almost like a square root function, so we will add column to the data with the square roots of this column; in this way, our model will still be linear in its coefficients but a root function in this feature.</p>

<p>The function <code class="highlighter-rouge">tuned_process</code> defined below processes the data by one-hot encoding the <code class="highlighter-rouge">University Rating</code> column (as before), adding in the square root of the <code class="highlighter-rouge">CGPA</code> column, and removing the <code class="highlighter-rouge">Research</code> column (using a helper function <code class="highlighter-rouge">drop_cols</code>). It returns the same items as <code class="highlighter-rouge">process_data</code> from earlier.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">drop_cols</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cols</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tuned_process</span><span class="p">(</span><span class="n">original_data</span><span class="p">):</span>
    <span class="s">"""
    Processes data for linear modeling
    """</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">original_data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    
    <span class="c"># one hot encode 'University Rating'</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>
                          <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'University Rating'</span><span class="p">],</span>
                          <span class="n">drop_first</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    
    <span class="c"># add in col with sqrt(cgpa)</span>
    <span class="n">data</span><span class="p">[</span><span class="s">'CGPA^0.5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'CGPA'</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span>
    
    <span class="c"># drop research</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">drop_cols</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'Research'</span><span class="p">)</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Chance of Admit'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Chance of Admit'</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</code></pre></div></div>

<p>In the cell below, we apply our fined-tuned model to the same dataset and look at the new RMSEs.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tuned_model</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>

<span class="n">X_train_tuned</span><span class="p">,</span> <span class="n">y_train_tuned</span> <span class="o">=</span> <span class="n">tuned_process</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">X_test_tuned</span><span class="p">,</span> <span class="n">y_test_tuned</span> <span class="o">=</span> <span class="n">tuned_process</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">tuned_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_tuned</span><span class="p">,</span> <span class="n">y_train_tuned</span><span class="p">)</span>
<span class="n">y_fitted_tuned</span> <span class="o">=</span> <span class="n">tuned_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_tuned</span><span class="p">)</span>
<span class="n">y_predicted_tuned</span> <span class="o">=</span> <span class="n">tuned_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_tuned</span><span class="p">)</span>

<span class="c"># calculate RMSE of prediction</span>
<span class="n">train_rmse_tuned</span> <span class="o">=</span> <span class="n">rmse</span><span class="p">(</span><span class="n">y_fitted_tuned</span><span class="p">,</span> <span class="n">y_train_tuned</span><span class="p">)</span>
<span class="n">test_rmse_tuned</span> <span class="o">=</span> <span class="n">rmse</span><span class="p">(</span><span class="n">y_predicted_tuned</span><span class="p">,</span> <span class="n">y_test_tuned</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Training RMSE: {}</span><span class="se">\n</span><span class="s">Test RMSE: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_rmse_tuned</span><span class="p">,</span> <span class="n">test_rmse_tuned</span><span class="p">))</span>
</code></pre></div></div>

<div class="output output_stream highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training RMSE: 0.06153302769443445
Test RMSE: 0.06996680529504397

</code></pre></div></div>

<p>To see if our model improved much, we can check the reduction in RMSE by comparing the original RMSEs to the new RMSEs:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># calculate reduction in RMSE</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training RMSE Reduction: {}</span><span class="se">\n</span><span class="s">Test RMSE Reduction: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">train_rmse</span> <span class="o">-</span> <span class="n">train_rmse_tuned</span><span class="p">,</span> <span class="n">test_rmse</span> <span class="o">-</span> <span class="n">test_rmse_tuned</span>
<span class="p">))</span>
</code></pre></div></div>

<div class="output output_stream highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training RMSE Reduction: -0.0009908159905003822
Test RMSE Reduction: 0.0005201863228481846

</code></pre></div></div>

<p>The modifications we made made very little impact on the RMSE, whether positive or negative, so our new model is, roughly speaking, about as good as our original model.</p>

<h3 id="bootstrapping-the-model">Bootstrapping the Model</h3>

<p>To get an idea of the steady-state RMSE of this model, we can bootstrap our dataset and look at the average RMSE across many repetitions. To begin this process, we define a function <code class="highlighter-rouge">run_lm</code> which automates the entire process of calculating the RMSE from <code class="highlighter-rouge">train_test_split</code> to the <code class="highlighter-rouge">rmse</code> function. It returns a 2-tuple with the training and testing RMSE.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_lm</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
    
    <span class="c"># split into training and test sets</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">admissions</span><span class="p">)</span>
    
    <span class="c"># initialize linear regression model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
    
    <span class="c"># process the data</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
    <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
    
    <span class="c"># fit the model to the training set</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c"># predict the training and testing outcomes</span>
    <span class="n">y_fitted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">y_predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="c"># calculate RMSE</span>
    <span class="n">train_rmse</span> <span class="o">=</span> <span class="n">rmse</span><span class="p">(</span><span class="n">y_fitted</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">test_rmse</span> <span class="o">=</span> <span class="n">rmse</span><span class="p">(</span><span class="n">y_predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">train_rmse</span><span class="p">,</span> <span class="n">test_rmse</span>
</code></pre></div></div>

<p>In the cell below, we bootstrap our data set 100,000 times and collect the training and testing RMSEs into lists, which we then average to look at the steady-state RMSE. We also seed <code class="highlighter-rouge">np.random</code> to ensure that the values we obtain are reproducible.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># bootstrap the data set</span>
<span class="n">reps</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">training_rmses</span><span class="p">,</span> <span class="n">testing_rmses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span> <span class="c"># seeding np.random for reproducibility</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">rmses</span> <span class="o">=</span> <span class="n">run_lm</span><span class="p">(</span><span class="n">admissions</span><span class="p">,</span> <span class="n">tuned_process</span><span class="p">)</span>
    <span class="n">training_rmses</span> <span class="o">+=</span> <span class="p">[</span><span class="n">rmses</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">testing_rmses</span> <span class="o">+=</span> <span class="p">[</span><span class="n">rmses</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    
<span class="k">print</span><span class="p">(</span><span class="s">'Average Training RMSE: {}</span><span class="se">\n</span><span class="s">Average Test RMSE: {}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">training_rmses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">testing_rmses</span><span class="p">)</span>
<span class="p">))</span>
</code></pre></div></div>

<div class="output output_stream highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average Training RMSE: 0.06315478365047726
Average Test RMSE: 0.06519462752608964

</code></pre></div></div>

<h2 id="sources">Sources</h2>

<p>Mohan S Acharya, Asfia Armaan, Aneeta S Antony : A Comparison of Regression Models for Prediction of Graduate Admissions, IEEE International Conference on Computational Intelligence in Data Science 2019</p>

              <nav class="c-page__nav">
  
    
    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/notebooks/avocado/avocado">
      〈 <span class="u-margin-right-tiny"></span> avocado.ipynb
    </a>
  

  
    
    <a id="js-page__nav__next" class="c-page__nav__next" href="/notebooks/movies/movies">
      movies.ipynb <span class="u-margin-right-tiny"></span> 〉
    </a>
  
</nav>

            </div>
          </div>
        </div>
      </main>
    </div>

  </body>
</html>
